{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A requirement to run this notebook is to already have a folder with images, with their respective coordinates and heading angle information written in their file name \n",
    "\n",
    "The file names should follow the pattern: <latitude>,<longitude>_<angle>.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = ENTER PATH HERE # TODO\n",
    "\n",
    "def img_load_func(img_path):\n",
    "    return cv2.imread(img_path)\n",
    "\n",
    "def fix_read_cols(df, cols):\n",
    "    not_nan = lambda x: not isinstance(x, float) or np.isfinite(x)\n",
    "    for col in cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].transform(lambda x: literal_eval(x) if not_nan(x) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images dataframe\n"
     ]
    }
   ],
   "source": [
    "imgs_df_path = data_path + 'extended_center_imgs_df.csv'\n",
    "imgs_folder_path = data_path + 'images/extended_center_pics/'\n",
    "\n",
    "if os.path.exists(imgs_df_path):\n",
    "    df = pd.read_csv(imgs_df_path)\n",
    "    fix_read_cols(df, ['img_shape'])\n",
    "    print('Loading images dataframe')\n",
    "else:\n",
    "    imgs_paths = glob(imgs_folder_path + '*.jpg')\n",
    "\n",
    "    df_dict = []\n",
    "\n",
    "    for path in imgs_paths:\n",
    "        _, filename = os.path.split(path)\n",
    "        lat = filename[:filename.find(',')]\n",
    "        lon = filename[filename.find(',') + 1:filename.find('_')]\n",
    "        angle = filename[filename.find('_') + 1:filename.rfind('.')]\n",
    "\n",
    "        df_dict += [{'img_path': os.path.normpath(path), 'img_lat': lat, 'img_lon': lon,\n",
    "                     'img_angle': angle, 'img_shape': img_load_func(path).shape}]\n",
    "        \n",
    "    df = pd.DataFrame(df_dict)\n",
    "    df['idx'] = np.arange(df.shape[0])\n",
    "\n",
    "    df.to_csv(imgs_df_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Detection and Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS2FIX = ['img_shape', 'real_detected_bboxes',\n",
    "            'real_img_shape', 'det_rect', 'detected_bbox']\n",
    "\n",
    "dset2path_col = {'synth':'synth_img_path', 'real':'img_path'}\n",
    "\n",
    "det_path = data_path + '/extended_center_det_df.csv'\n",
    "rec_path = data_path + '/extended_center_rec_df.csv'\n",
    "tmp_rec_path = data_path + '/extended_center_rec_tmp_df.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EAST.eval import east_detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading saved detections\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(det_path):\n",
    "    df = pd.read_csv(det_path)\n",
    "    fix_read_cols(df, COLS2FIX)\n",
    "    print('Reading saved detections')\n",
    "else:\n",
    "    det_tmp_path = data_path + '/tmp_detections/'\n",
    "\n",
    "    detections = east_detect(test_data_path=imgs_folder_path, gpu_list='0', \n",
    "                             checkpoint_path='./EAST/nets/',\n",
    "                             output_dir=det_tmp_path, max_im_height=620, nr_imgs=100)\n",
    "\n",
    "    df['real_detected_bboxes'] = df.img_path.transform(lambda path: detections[path] if path in detections else None)\n",
    "    df = df.dropna(subset=['real_detected_bboxes'])\n",
    "    df['real_detected_bboxes'] = df.real_detected_bboxes.transform(lambda boxes: [box.tolist() for box in boxes])\n",
    "    df.to_csv(det_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from citywords.text_det import is_valid_rec, box2rec\n",
    "\n",
    "unrolled = df.apply(lambda x: pd.Series(x['real_detected_bboxes']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "unrolled.name = 'real_detected_bbox'\n",
    "\n",
    "unrolled_df = df.join(unrolled)\n",
    "\n",
    "rect_lambda = lambda row: box2rec(row['real_detected_bbox'], row['img_shape'])\n",
    "\n",
    "unrolled_df[\"det_rect\"] = unrolled_df.apply(rect_lambda, axis=1)\n",
    "is_valid_rect = unrolled_df[\"det_rect\"].transform(lambda rect: is_valid_rec(*rect))\n",
    "\n",
    "unrolled_df = unrolled_df[is_valid_rect]\n",
    "\n",
    "unrolled_df[\"rec_idx\"] = unrolled_df.apply(lambda row: (row.idx, tuple(map(tuple, row[\"det_rect\"]))), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from citywords.text_det import crop_det\n",
    "\n",
    "cropped_folder_path = data_path + \"/cropped_imgs/\"\n",
    "\n",
    "def rec_idx2cropped_path(rec_idx):\n",
    "    return os.path.normpath(cropped_folder_path + os.sep + str(rec_idx) + \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(rec_path):\n",
    "    if not os.path.exists(cropped_folder_path):\n",
    "        os.makedirs(cropped_folder_path)\n",
    "\n",
    "    for _, row in unrolled_df.iterrows():\n",
    "        path = rec_idx2cropped_path(row.rec_idx)\n",
    "\n",
    "        if os.path.exists(path):\n",
    "            continue\n",
    "        else:\n",
    "            cropped_img = crop_det(img_load_func(row.img_path), row.det_rect)\n",
    "            cv2.imwrite(path, cropped_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_text_recognition_benchmark.demo import recognize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(rec_path):\n",
    "    det_rec_df = pd.read_csv(rec_path)\n",
    "else:\n",
    "    recognitions = recognize(image_folder=cropped_folder_path, \n",
    "                            saved_model='deep_text_recognition_benchmark/TPS-ResNet-BiLSTM-Attn.pth')\n",
    "    recognitions = {os.path.normpath(k): v for k, v in recognitions.items()}\n",
    "\n",
    "    unrolled_df['rec_txt'] = unrolled_df.rec_idx.transform(lambda idx: recognitions[rec_idx2cropped_path(idx)]['pred'])\n",
    "    unrolled_df['rec_conf'] = unrolled_df.rec_idx.transform(lambda idx: recognitions[rec_idx2cropped_path(idx)]['confidence_score'])\n",
    "    unrolled_df['rec_conf'] = pd.to_numeric(unrolled_df.rec_conf)\n",
    "\n",
    "    det_rec_df = unrolled_df\n",
    "\n",
    "    det_rec_df.to_csv(rec_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "\n",
    "from citywords.gpt import gpt_get_descriptions_and_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = data_path + \"gpt_result.pickle\"\n",
    "\n",
    "if os.path.exists(result_path):\n",
    "    with open(result_path, 'rb') as f:\n",
    "        descriptions = pickle.load(f)\n",
    "else:\n",
    "    descriptions = dict()\n",
    "\n",
    "chunk_size = 30\n",
    "\n",
    "words = list(det_rec_df.rec_txt[~det_rec_df.rec_txt.isin(descriptions.keys())].unique())\n",
    "words_part = list(np.random.choice(words, min(chunk_size, len(words)), replace=False))\n",
    "\n",
    "while words_part:\n",
    "    result = gpt_get_descriptions_and_topics(words_part, custom_prompt=None)\n",
    "    result = literal_eval(result)\n",
    "\n",
    "    descriptions = {**descriptions, **result}\n",
    "\n",
    "    with open(result_path, 'wb') as f:\n",
    "        pickle.dump(descriptions, f)\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    words = list(det_rec_df.rec_txt[~det_rec_df.rec_txt.isin(descriptions.keys())].unique())\n",
    "    words_part = list(np.random.choice(words, min(chunk_size, len(words)), replace=False))\n",
    "\n",
    "    print('words left:', len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from citywords.w2v import TransformerEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sentence lenght: 128\n",
      "loading embeds\n"
     ]
    }
   ],
   "source": [
    "embd_save_path = data_path + 'embds_extended_center.pickle'\n",
    "\n",
    "encoder = TransformerEncoder(model_name='xlm-r-100langs-bert-base-nli-stsb-mean-tokens')\n",
    "\n",
    "if os.path.exists(embd_save_path):\n",
    "    print('loading embeds')\n",
    "    with open(embd_save_path, 'rb') as f:\n",
    "        embd_dict = pickle.load(f)\n",
    "else:            \n",
    "    words = descriptions.keys()\n",
    "    texts = [descriptions[key] for key in words]\n",
    "\n",
    "    embds = encoder.encode(texts).cpu().numpy()\n",
    "    embd_dict = {word:embds[i] for i, word in enumerate(words)}\n",
    "            \n",
    "    with open(embd_save_path, 'wb') as f:\n",
    "        pickle.dump(embd_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from citywords.analysis import classify_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_descriptions = {'alimentacao': 'restaurantes, bares, mercados, cafes, e outros estabelecimentos relacionados a compra de comida e bebidas.',\n",
    "                      'imoveis': 'placas de aluga-se, vende-se, corretores de imóveis ou nomes de imobiliarias, placas que indicam construção.',\n",
    "                      'saude e bem estar': 'hospitais, farmacias, clínicas médicas, clínicas estéticas, qualquer estabelecimento relacionado a tratamentos para a saúde, estética ou bem estar.',\n",
    "                      'lazer e entretenimento': 'cinemas, teatros, hoteis, casas de show, centros esportivos, quadras, parques e qualquer tipo de estabelecimento destinado a entretenimento ou lazer das pessoas.',\n",
    "                      'escolar': 'escolas, transporte escolar, universidades, faculdades, escolas de idiomas, qualquer estabelecimento ligado a educação e treinamento em geral.',\n",
    "                      'transporte': 'estacionamentos, vagas para veículos, lojas de auto peças, aluguel de veículos, garagens, concessionarias de venda de veículos novos, semi novos ou usados.',\n",
    "                      'religiao': 'estabelecimentos religiosos, igrejas, centros religiosos.',\n",
    "                      'comercio': 'lojas em geral, roupas, calçados, jóias, presentes, brinquedos, eletrônicos, móveis, lojas de departamento.',\n",
    "                      'financeiro': 'bancos, caixas eletrônicos, agencias financeiras em geral.',\n",
    "                      'servicos': 'cartório, serviços de advocacia, escritórios, serviços de reparos.',\n",
    "                      'sinalizacao e locais': 'placas de trânsito, placas com nomes de ruas, nomes de país, cidade, bairro ou região, sinalização de aviso, atenção e proibição.'}\n",
    "\n",
    "det_rec_df = classify_topics(det_rec_df, embd_dict, encoder, topic_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>img_path</th>\n",
       "      <th>img_lat</th>\n",
       "      <th>img_lon</th>\n",
       "      <th>img_angle</th>\n",
       "      <th>img_shape</th>\n",
       "      <th>idx</th>\n",
       "      <th>real_detected_bboxes</th>\n",
       "      <th>real_detected_bbox</th>\n",
       "      <th>det_rect</th>\n",
       "      <th>rec_idx</th>\n",
       "      <th>rec_txt</th>\n",
       "      <th>rec_conf</th>\n",
       "      <th>topic_cls_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>G:\\My Drive\\Master\\data\\images\\extended_center...</td>\n",
       "      <td>-23.574498</td>\n",
       "      <td>-46.667948</td>\n",
       "      <td>338.960</td>\n",
       "      <td>(640, 640, 3)</td>\n",
       "      <td>6</td>\n",
       "      <td>[[[412, 232], [443, 233], [443, 246], [412, 24...</td>\n",
       "      <td>[[412, 232], [443, 233], [443, 246], [412, 245]]</td>\n",
       "      <td>([412, 232], [443, 246])</td>\n",
       "      <td>(6, ((412, 232), (443, 246)))</td>\n",
       "      <td>shissant</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>sinalizacao e locais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>G:\\My Drive\\Master\\data\\images\\extended_center...</td>\n",
       "      <td>-23.574498</td>\n",
       "      <td>-46.667948</td>\n",
       "      <td>338.960</td>\n",
       "      <td>(640, 640, 3)</td>\n",
       "      <td>6</td>\n",
       "      <td>[[[412, 232], [443, 233], [443, 246], [412, 24...</td>\n",
       "      <td>[[441, 234], [470, 235], [470, 248], [441, 247]]</td>\n",
       "      <td>([441, 234], [470, 248])</td>\n",
       "      <td>(6, ((441, 234), (470, 248)))</td>\n",
       "      <td>tishop</td>\n",
       "      <td>0.062474</td>\n",
       "      <td>sinalizacao e locais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>G:\\My Drive\\Master\\data\\images\\extended_center...</td>\n",
       "      <td>-23.574442</td>\n",
       "      <td>-46.632113</td>\n",
       "      <td>203.625</td>\n",
       "      <td>(640, 640, 3)</td>\n",
       "      <td>9</td>\n",
       "      <td>[[[-1, 331], [52, 330], [52, 344], [-1, 345]],...</td>\n",
       "      <td>[[-1, 331], [52, 330], [52, 344], [-1, 345]]</td>\n",
       "      <td>([0, 331], [52, 344])</td>\n",
       "      <td>(9, ((0, 331), (52, 344)))</td>\n",
       "      <td>rearial</td>\n",
       "      <td>0.169805</td>\n",
       "      <td>sinalizacao e locais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>G:\\My Drive\\Master\\data\\images\\extended_center...</td>\n",
       "      <td>-23.574442</td>\n",
       "      <td>-46.632113</td>\n",
       "      <td>203.625</td>\n",
       "      <td>(640, 640, 3)</td>\n",
       "      <td>9</td>\n",
       "      <td>[[[-1, 331], [52, 330], [52, 344], [-1, 345]],...</td>\n",
       "      <td>[[49, 330], [105, 331], [105, 343], [49, 343]]</td>\n",
       "      <td>([49, 330], [105, 343])</td>\n",
       "      <td>(9, ((49, 330), (105, 343)))</td>\n",
       "      <td>camarimi</td>\n",
       "      <td>0.844555</td>\n",
       "      <td>sinalizacao e locais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>G:\\My Drive\\Master\\data\\images\\extended_center...</td>\n",
       "      <td>-23.572943</td>\n",
       "      <td>-46.632123</td>\n",
       "      <td>313.703</td>\n",
       "      <td>(640, 640, 3)</td>\n",
       "      <td>16</td>\n",
       "      <td>[[[418, 173], [564, 149], [568, 178], [423, 20...</td>\n",
       "      <td>[[418, 173], [564, 149], [568, 178], [423, 202]]</td>\n",
       "      <td>([418, 173], [568, 178])</td>\n",
       "      <td>(16, ((418, 173), (568, 178)))</td>\n",
       "      <td>some</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>escolar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  \\\n",
       "0           6             6   \n",
       "0           6             6   \n",
       "1           9             9   \n",
       "1           9             9   \n",
       "2          16            16   \n",
       "\n",
       "                                            img_path    img_lat    img_lon  \\\n",
       "0  G:\\My Drive\\Master\\data\\images\\extended_center... -23.574498 -46.667948   \n",
       "0  G:\\My Drive\\Master\\data\\images\\extended_center... -23.574498 -46.667948   \n",
       "1  G:\\My Drive\\Master\\data\\images\\extended_center... -23.574442 -46.632113   \n",
       "1  G:\\My Drive\\Master\\data\\images\\extended_center... -23.574442 -46.632113   \n",
       "2  G:\\My Drive\\Master\\data\\images\\extended_center... -23.572943 -46.632123   \n",
       "\n",
       "   img_angle      img_shape  idx  \\\n",
       "0    338.960  (640, 640, 3)    6   \n",
       "0    338.960  (640, 640, 3)    6   \n",
       "1    203.625  (640, 640, 3)    9   \n",
       "1    203.625  (640, 640, 3)    9   \n",
       "2    313.703  (640, 640, 3)   16   \n",
       "\n",
       "                                real_detected_bboxes  \\\n",
       "0  [[[412, 232], [443, 233], [443, 246], [412, 24...   \n",
       "0  [[[412, 232], [443, 233], [443, 246], [412, 24...   \n",
       "1  [[[-1, 331], [52, 330], [52, 344], [-1, 345]],...   \n",
       "1  [[[-1, 331], [52, 330], [52, 344], [-1, 345]],...   \n",
       "2  [[[418, 173], [564, 149], [568, 178], [423, 20...   \n",
       "\n",
       "                                 real_detected_bbox                  det_rect  \\\n",
       "0  [[412, 232], [443, 233], [443, 246], [412, 245]]  ([412, 232], [443, 246])   \n",
       "0  [[441, 234], [470, 235], [470, 248], [441, 247]]  ([441, 234], [470, 248])   \n",
       "1      [[-1, 331], [52, 330], [52, 344], [-1, 345]]     ([0, 331], [52, 344])   \n",
       "1    [[49, 330], [105, 331], [105, 343], [49, 343]]   ([49, 330], [105, 343])   \n",
       "2  [[418, 173], [564, 149], [568, 178], [423, 202]]  ([418, 173], [568, 178])   \n",
       "\n",
       "                          rec_idx   rec_txt  rec_conf       topic_cls_label  \n",
       "0   (6, ((412, 232), (443, 246)))  shissant  0.001355  sinalizacao e locais  \n",
       "0   (6, ((441, 234), (470, 248)))    tishop  0.062474  sinalizacao e locais  \n",
       "1      (9, ((0, 331), (52, 344)))   rearial  0.169805  sinalizacao e locais  \n",
       "1    (9, ((49, 330), (105, 343)))  camarimi  0.844555  sinalizacao e locais  \n",
       "2  (16, ((418, 173), (568, 178)))      some  0.020000               escolar  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det_rec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_rec_df.to_csv(data_path + 'extended_center_final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_semantic_spacial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
